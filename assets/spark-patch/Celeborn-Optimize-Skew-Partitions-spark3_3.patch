# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

diff --git a/sql/catalyst/src/main/scala/org/apache/spark/sql/internal/SQLConf.scala b/sql/catalyst/src/main/scala/org/apache/spark/sql/internal/SQLConf.scala
index af03ad9a4cb..7a3ee9ebfaf 100644
--- a/sql/catalyst/src/main/scala/org/apache/spark/sql/internal/SQLConf.scala
+++ b/sql/catalyst/src/main/scala/org/apache/spark/sql/internal/SQLConf.scala
@@ -3784,6 +3784,12 @@ object SQLConf {
     .booleanConf
     .createWithDefault(false)
 
+  val CELEBORN_CLIENT_ADAPTIVE_OPTIMIZE_SKEWED_PARTITION_READ =
+    buildConf("spark.celeborn.client.adaptive.optimizeSkewedPartitionRead.enabled")
+      .version("3.0.0")
+      .booleanConf
+      .createWithDefault(false)
+
   /**
    * Holds information about keys that have been deprecated.
    *
@@ -4549,6 +4555,9 @@ class SQLConf extends Serializable with Logging {
   def histogramNumericPropagateInputType: Boolean =
     getConf(SQLConf.HISTOGRAM_NUMERIC_PROPAGATE_INPUT_TYPE)
 
+  def celebornClientAdaptiveOptimizeSkewedPartitionReadEnabled: Boolean =
+    getConf(SQLConf.CELEBORN_CLIENT_ADAPTIVE_OPTIMIZE_SKEWED_PARTITION_READ)
+
   /** ********************** SQLConf functionality methods ************ */
 
   /** Set Spark SQL configuration properties. */
diff --git a/sql/core/src/main/scala/org/apache/spark/sql/execution/adaptive/ShufflePartitionsUtil.scala b/sql/core/src/main/scala/org/apache/spark/sql/execution/adaptive/ShufflePartitionsUtil.scala
index af689db3379..f277bc396d4 100644
--- a/sql/core/src/main/scala/org/apache/spark/sql/execution/adaptive/ShufflePartitionsUtil.scala
+++ b/sql/core/src/main/scala/org/apache/spark/sql/execution/adaptive/ShufflePartitionsUtil.scala
@@ -22,6 +22,7 @@ import scala.collection.mutable.ArrayBuffer
 import org.apache.spark.{MapOutputStatistics, MapOutputTrackerMaster, SparkEnv}
 import org.apache.spark.internal.Logging
 import org.apache.spark.sql.execution.{CoalescedPartitionSpec, PartialReducerPartitionSpec, ShufflePartitionSpec}
+import org.apache.spark.sql.internal.SQLConf
 
 object ShufflePartitionsUtil extends Logging {
   final val SMALL_PARTITION_FACTOR = 0.2
@@ -387,6 +388,23 @@ object ShufflePartitionsUtil extends Logging {
     val mapStartIndices = splitSizeListByTargetSize(
       mapPartitionSizes, targetSize, smallPartitionFactor)
     if (mapStartIndices.length > 1) {
+      val isCelebornClientAdaptiveOptimizeSkewedPartitionReadEnabled =
+        // TODO: check fallback or not.
+        SparkEnv.get.conf.get("spark.shuffle.manager", "sort").contains("celeborn") &&
+          SQLConf.get.celebornClientAdaptiveOptimizeSkewedPartitionReadEnabled
+
+      val throwsFetchFailure = SparkEnv.get
+        .conf
+        .get("spark.celeborn.client.spark.fetch.throwsFetchFailure", "false")
+        .toBoolean
+      if (throwsFetchFailure && isCelebornClientAdaptiveOptimizeSkewedPartitionReadEnabled) {
+        throw new UnsupportedOperationException(
+          "Currently, the 'Optimize Skewed Partition Read' feature cannot be used " +
+            "together with the 'Stage Re-run' feature. (The configuration parameters " +
+            "`spark.celeborn.client.spark.fetch.throwsFetchFailure` and " +
+            "`spark.celeborn.client.adaptive.optimizeSkewedPartitionRead.enabled` cannot be set " +
+            "to `true` at the same time.)")
+      }
       Some(mapStartIndices.indices.map { i =>
         val startMapIndex = mapStartIndices(i)
         val endMapIndex = if (i == mapStartIndices.length - 1) {
@@ -400,7 +418,14 @@ object ShufflePartitionsUtil extends Logging {
           dataSize += mapPartitionSizes(mapIndex)
           mapIndex += 1
         }
-        PartialReducerPartitionSpec(reducerId, startMapIndex, endMapIndex, dataSize)
+        if (isCelebornClientAdaptiveOptimizeSkewedPartitionReadEnabled) {
+          // These `dataSize` variables may not be accurate as they only represent the sum of
+          // `dataSize` when the Celeborn optimize skewed partition read feature is enabled.
+          // Please not to use these dataSize variables in any other part of the codebase.
+          PartialReducerPartitionSpec(reducerId, mapStartIndices.length, i, dataSize)
+        } else {
+          PartialReducerPartitionSpec(reducerId, startMapIndex, endMapIndex, dataSize)
+        }
       })
     } else {
       None
